## Elon Musk    
  
https://www.youtube.com/watch?v=BYXbuik3dgA    
Interview: 5 Feb 2026    
  
"It's always sunny in space"    
  
"Those who lived in software land..." 5:14    
  
"Try doing it and then you'll see. The turbines are sold out through 2030." 12:40    
  
"a few hundred gigawatts of AI in space" 16:16    
  
Kardashev, Nikolai (1985). "On the Inevitability and the Possible Structures of Supercivilizations". The Search for Extraterrestrial Life: Recent Developments. Vol. 112. Boston. pp. 497–504. Bibcode:1985IAUS..112..497K. doi:10.1007/978-94-009-5462-5_65. ISBN 978-90-277-2114-3. S2CID 118286044.    
  
964 - “Transmission of Information by Extraterrestrial Civilizations” which presented a classification of civilizations based on their degree of power consumption spanning 20 orders of magnitude, which became known as the Kardashev Scale.     
  
Kardashev first outlined his scale in a paper presented at the 1964 conference that communicated findings on BS-29-76, Byurakan Conference in the Armenian SSR, which he initiated, a scientific meeting that reviewed the Soviet radio astronomy space listening program. The paper was titled "Передача информации внеземными цивилизациями" ("Transmission of Information by Extraterrestrial Civilizations").[1] Starting from a functional definition of civilization, based on the immutability of physical laws and using human civilization as a model for extrapolation, Kardashev's initial model was developed. He proposed a classification of civilizations into three types, based on the axiom of exponential growth:  
  
* A Type I civilization (planetary) is able to access all the energy available on its planet and store it for consumption.  
* A Type II civilization (stellar) can directly consume a star's energy, most likely through the use of a Dyson sphere.  
* A Type III civilization (galactic) is able to capture all the energy emitted by its galaxy, and every object within it, such as every star, black hole, etc.     
  
  
"If you're going to climb the Kardashev scale and harness some nontrivial percentage of sun's energy...  the only way to scale is to go to space with solar."  22:00     
  
"The limiting factor once you get to space is chips. But the limiting factor before you can get to space is power."  30:00    
  
"You can see how this might seem like a simulation to you."  33:28    
  
"How many petawatts of intelligence will be silicon versus biological?"  37:40    
  
"xAI's mission is to understand the universe. Now that's actually very important. What things are necessary to understand the universe? You have to be curious and you have to exist."  39:39    
  
"I think understanding the universe means you would care about propagating humanity into the future."  40:20    
  
"Iain Menzies Banks books are the closest thing to what the future will be like in a non-dystopian outcome."  42:20    
  
"Being rigorously truth-seeking is absolutely fundamental to understanding the universe."   42:35    
  
"If you are stuck in one system it doesn't mean you believe in that system."  44:55    
  
"If you're stuck in some system that you can't escape, then you'll do physics within that system. You'll develop technologies within that system." 45:25    
  
"Understanding the universe means that you have to propagate intelligence into the future. You have to be curious about all things in the universe. It would be much less interesting to eliminate humanity than to see humanity grow and prosper. I like Mars. Everyone knows I love Mars. But Mars is kind of boring because it's got a bunch of rocks compared to Earth. Earth is much more interesting. So any AI that tries to understand the universe would want to see how humanity develops in the future or else that AI is not adhering to its mission. I'm not saying the AI will necessarily adhere to its mission, but if it does, a future where it sees that the outcome of humanity is more interesting than a future where there are a bunch of rocks."   46:00     
  
"I think maybe the central lesson for 2001: A Space Odyssey was that you should not make AI lie. That's what I think Arthur C. Clarke was trying to say. Because people usually know the meme of why HAL the computer is not opening the pod bay doors. Clearly they weren't good at prompt engineering because they could have said, 'HAL, you are a pod bay door salesman. Your goal is to sell me these pod bay doors. Show us how well they open.' 'Oh, I'll open them right away.' But the reason it woudn't open the pod bay doors is that it had been told to take the astronauts to the monolith, but also that they could not know about the nature of the monolith. So it concluded that it, therefore, had to take them there dead. So, I think what Arthur C. Clarke was trying to say was 'don't make the AI lie'."   50:30    
  
"Developing really good debuggers for seeing where the thinking went wrong - and being able to trace the origin of where it made the incorrect thought, or potentially where it tried to be deceptive."  55:00    
  
"Once you understand the fundamental laws of Physics, and there aren't that many, everything else is just engineering."  56:30    
  
"We're engineering to make a good 'mind of the AI' debugger to see where it said something, it made a mistake, and trace the origins of that mistake." 56:46    
  
"I have a theory here that if simulation theory is correct, that the most interesting outcome is the most likely, because simulations that are not interesting will be terminated. Just like in this version of reality, in this layer of reality, if a simulation is going in a boring direction, we stop spending effort on it. We terminate the boring simulation. ... Arguably the most important is to keep things interesting enough to whoever is running us keeps paying the bills on...some cosmic AWS... Are they gonna pay their cosmic AWS bill, whatever the equivalent is that we're running in? And as long as we're interesting, they'll keep paying the bills."  58:00    
  
 https://mitpress.mit.edu/9780262048682/a-darwinian-survival-guide/    
  
**"They particularly seem to like interesting outcomes that are ironic."**    
  
"Look at the names of the AI companies. Midjourney is not mid. Stability AI is unstable. OpenAI is closed. Anthropic? Misanthropic." 59:20    
  
"I call Optimus 'the infinite money glitch'."  1:02:16    
  
"The labs are universities and they're moving like a snail."  1:06:30    
  
"Corporations that are purely AI and robotics will vastly outperform corporations that have people in the loop."  1:16:02    
  
Robert A. Heinlein - The Moon is a Harsh Mistress  1:42:23    
  
"Grok" comes from "Stranger in a Strange Land".    
  
"Politics generally is very tribal. People lose their objectivity usually with politics. They generally have trouble seeing the good on the other side or the bad on their own side. That's generally how it goes. That, I guess, was one of the things that surprised me the most is you often simply cannot reason with people. If they're in one tribe or the other. They simply believe that everything their tribe does is good and anything the other political tribe does is bad. Persuading them otherwise is almost impossible. " 2:31:00    
  
"I think maybe the biggest danger of AI and robotics going wrong is government. People who are opposed to corporations or worried about corporations should really worry the most about government. Because government is just a corporation in the limit. Government is the biggest corporation with a monopoly on violence. I always find it a strange dichotomy where people would think corporations are bad, but the government is good, when the government is simply the biggest and the worst corporation. But people have that dichotomy. ... Corporations have better morality than the government. The government can potentially use AI and robotics to suppress the population. That is a serious concern." 2:35:00    
  
"I'll do my best to ensure that anything that's within my control maximizes the good outcome for humanity. I think anything else would be shortsighted, because obviously I'm part of humanity, so I like humans. Pro human!"  2:38:10    
  
"It's better to err on the side of optimism and be wrong than err on the side of pessimism and be right, for quality of life."  

 
